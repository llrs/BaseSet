---
title: "Fuzzy sets"
abstract: >
  Describes the fuzzy sets, interpretation and how to work with them.
output:
  html_document:
    fig_caption: true
    code_folding: show
    self_contained: yes
    toc_float:
      collapsed: true
      toc_depth: 3
author:
- name: Lluís Revilla
  affiliation: 
    - August Pi i Sunyer Biomedical Research Institute (IDIBAPS); Liver Unit, Hospital Clinic
  email: lluis.revilla@gmail.com
vignette: >
  %\VignetteIndexEntry{2. Fuzzy sets}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_knit$set(root.dir = ".")
knitr::opts_chunk$set(collapse = TRUE, 
                      warning = TRUE,
                      comment = "#>")
library("BaseSet")
library("dplyr")
```


# Getting started

This vignettes supposes that you already read the "About BaseSet" vignette. 
This vignette explains what are the fuzzy sets and how to use them. 
As all methods for "normal" sets are available for fuzzy sets this vignette focuses on how to create, use them.

# What are fuzzy sets and why/when use them ?

Fuzzy sets are generalizations of classical sets where there is some vagueness, one doesn't know for sure something on this relationship between the set and the element.
This vagueness can be on the assignment to a set and/or on the membership on the set.
One way these vagueness arise is when classifying a continuous scale on a categorical scale, for example: when the temperature is 20ºC is it hot or not? If the temperature drops to 15ºC is it warm?
When does the switch happen from warm to hot?

In fuzzy set theories the step from a continuous scale to a categorical scale is performed by the [membership function](https://en.wikipedia.org/wiki/Membership_function_(mathematics)) and is called [fuzzification](https://en.wikipedia.org/wiki/Fuzzy_logic#Fuzzification). 

When there is a degree of membership and uncertainty on the membership it is considered a [type-2 fuzzy set](https://en.wikipedia.org/wiki/Type-2_fuzzy_sets_and_systems).
We can understand it with using as example a paddel ball, it can be used for tennis or paddel (membership), but until we don't test it bouncing on the court we won't be sure (assignment) if it is a paddel ball or a tennis ball. 
We could think about a ball equally good for tennis and paddel (membership) but which two people thought it is for tennis and the other for paddel. 

These voting/rating system is also a common scenario where fuzzy sets arise.
When several graders/people need to agree but compromise on a middle ground. 

# Creating a fuzzy set


To create a fuzzy set you need to have a column named "fuzzy" if you create it 
from a `data.frame` or have a named numeric vector if you create it from a `list`.
These values are restricted to a numeric value between 0 and 1. 
The value indicates the strength, membership, truth value (or probability) of the relationship between 
the element and the set. 

```{r fuzzy}
set.seed(4567) # To be able to have exact replicates
relations <- data.frame(sets = c(rep("A", 5), "B", "C"),
                          elements = c(letters[seq_len(6)], letters[6]),
                          fuzzy = runif(7))
fuzzy_set <- tidySet(relations)
```


# Working with fuzzy sets

We can work with fuzzy sets as we do with normal sets. But if you remember that at the end of the vignette we used an Important column now this is already included, which allows us to use this information for union and intersection methods:

## Union

You can make a union of two sets present on the same object.

```{r union}
BaseSet::union(fuzzy_set, sets = c("C", "B"), name = "D")
BaseSet::union(fuzzy_set, sets = c("C", "B"), name =  "D", FUN = "mean")
```

Observe the fuzziness on the resulting set has changed (on the traditional sets it doesn't matter)

## Intersection

We can do the same with the intersection

```{r intersection}
intersection(fuzzy_set, sets = c("A", "B"), keep = FALSE)
intersection(fuzzy_set, sets = c("A", "B"), keep = FALSE, FUN = "mean")
```

But in this example we don't see any difference on the calculated values.

## Complement

We can look for the complement of one or several sets:

```{r complement}
complement_set(fuzzy_set, sets = "A", keep = FALSE)
```

Note that the values of the complement are `1-fuzzy`:

```{r complement_previous}
fuzzy_set %>% filter(sets == "A")
```

## Subtract

This is the equivalent of `setdiff`, but clearer:

```{r subtract}
subtract(fuzzy_set, set_in = "A", not_in = "B", keep = FALSE, name = "A-B")
# Or the opposite B-A, but using the default name:
subtract(fuzzy_set, set_in = "B", not_in = "A", keep = FALSE)
```

Note that here there is also a subtraction of the fuzzy value.

# Sizes

Note that here the size of a set is not fixed:
```{r set_size}
set_size(fuzzy_set)
```

Or an element can be in 0 sets:

```{r element_size}
element_size(fuzzy_set)
```

In this example we can see that it is more probable that the element A is not 
present than the element f being present in one set. 

# Interpretation

Let's dive a bit in the interpretation.

Imagine you have your experiment where you collected data from a sample of cells for each cell (our elements). 
Then you used some program to classify which type of cell it is (delta endothelial, alpha, beta), this are our sets. 
The software returns a score (between 0 and 1) for each type it has, the higher the more confident it is of the assignment, which is our fuzzy value:

```{r cells_0}
sc_classification <- data.frame(
  elements = c("D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", 
               "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18", "D2ex_1", "D2ex_10", 
               "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", "D2ex_15", "D2ex_16",
               "D2ex_17", "D2ex_18", "D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", 
               "D2ex_13", "D2ex_14", "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18", 
               "D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", 
               "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18"), 
  sets = c("alpha", "alpha", "alpha", "alpha", "alpha", "alpha", "alpha", 
           "alpha", "alpha", "alpha", "endothel", "endothel", "endothel", 
           "endothel", "endothel", "endothel", "endothel", "endothel", 
           "endothel", "endothel", "delta", "delta", "delta", "delta", "delta", 
           "delta", "delta", "delta", "delta", "delta", "beta", "beta", "beta", 
           "beta", "beta", "beta", "beta", "beta", "beta", "beta"), 
  fuzzy = c(0.18, 0.169, 0.149, 0.192, 0.154, 0.161, 0.169, 0.197, 0.162, 0.201, 
            0.215, 0.202, 0.17, 0.227, 0.196, 0.215, 0.161, 0.195, 0.178, 
            0.23, 0.184, 0.172, 0.153, 0.191, 0.156, 0.167, 0.165, 0.184, 
            0.162, 0.194, 0.197, 0.183, 0.151, 0.208, 0.16, 0.169, 0.169, 
            0.2, 0.154, 0.208), stringsAsFactors = FALSE)
head(sc_classification)
```

Our question is which type of cells did we have on the original sample?
We can easily answer this by looking at the relations that have higher confidence of the relationship for each cell.

```{r cells_classification}
sc_classification <- tidySet(sc_classification)
cells_assigned <- sc_classification %>% 
  activate("relations") %>% 
  group_by(elements) %>% 
  filter(fuzzy == max(fuzzy))
cells_assigned
# See how many cells of each type we have
cells_assigned %>% 
  group_by(sets) %>% 
  count()
```

Now we know which is the cell type most probable for each cell, and how much of each type we have.
Let's see how many cells of each type we are more likely to get:

```{r cells_subset}
sample_cells <- sc_classification %>% 
  set_size() %>% 
  group_by(sets) %>% 
  filter(probability == max(probability))
sample_cells
```

And we can see that there are `r paste(apply(sample_cells[, 1:2], 1, function(x){paste0(x[2], " ", x[1], " cells,")}), collapse = " ")`. 
But this doesn't make sense, because there must be some cell misclassification: we have only `r nElements(sc_classification)` cells in this example but there are `r sum(sample_cells$size)` cells predicted for these types:
```{r}
nElements(sc_classification) == sum(sample_cells$size)
```
Ideally the predicted number of cells per type and the cells with higher confidence about the type should match. 

We can also look the other way around: How good is the prediction of a cell type for each cell? 

```{r}
cells_type <- sc_classification %>% 
  element_size() %>% 
  group_by(elements) %>% 
  filter(probability == max(probability))
cells_type
```

We can see that for most cells the most probable cell type is not present (we don't know the type of cell), and some cells could be classified in more than 1 cell type.

```{r}
sc_classification %>% 
  element_size() %>% 
  filter(elements == "D2ex_18") %>% 
  arrange(desc(probability))
```

And as we can see it is mostly as likely to be on the three cell types than in none of the cell types present.
